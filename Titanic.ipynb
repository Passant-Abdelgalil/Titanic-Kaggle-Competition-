{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Labiraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Read & Separate) samples & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "#separate the target col\n",
    "train_label = train_data.Survived\n",
    "#Store the Ids as indcies for the df\n",
    "train_data.index = train_data['PassengerId']\n",
    "# Drop unused cols\n",
    "features_toDrop = ['Survived', 'Ticket', 'Cabin', 'Name', 'PassengerId']\n",
    "train_data = train_data.drop(features_toDrop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Fsize_feature(data):\n",
    "    \n",
    "    # Create new feature (family size)\n",
    "    data[\"Fsize\"] = data[\"SibSp\"] + data[\"Parch\"] + 1\n",
    "    \n",
    "    # encode the family size feature\n",
    "    data['Single'] = data['Fsize'].map(lambda s: 1 if s == 1 else 0)\n",
    "    data['SmallF'] = data['Fsize'].map(lambda s: 1 if  s == 2  else 0)\n",
    "    data['MedF'] = data['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n",
    "    data['LargeF'] = data['Fsize'].map(lambda s: 1 if s >= 5 else 0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sex_embark_encode(data):\n",
    "    \n",
    "    data['Sex'] = data['Sex'].astype('category')\n",
    "    data['Sex'] = data['Sex'].cat.codes\n",
    "    \n",
    "    data['Embarked'] = data['Embarked'].fillna('S') \n",
    "    data['Embarked'] = data['Embarked'].astype('category')\n",
    "    data['Embarked'] = data['Embarked'].cat.codes\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_Fsize_feature(train_data)\n",
    "train_data = sex_embark_encode(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe columns are:\n",
      "\n",
      "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Fsize',\n",
      "       'Single', 'SmallF', 'MedF', 'LargeF'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataframe columns are:\\n\")\n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Age is: 29.69911764705882\n"
     ]
    }
   ],
   "source": [
    "Mean = train_data.loc[:,'Age'].mean()\n",
    "print(\"Mean of Age is:\", Mean)\n",
    "train_data['Age'] = train_data['Age'].fillna(Mean) # Fill the nan values with the mean of Age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nan values in Age Col is:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of nan values in Age Col is: \",train_data['Age'].isnull().sum()) # Check for nan values in Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "Number of nan values in the whole df:\n",
      " Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "Fsize       0\n",
      "Single      0\n",
      "SmallF      0\n",
      "MedF        0\n",
      "LargeF      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(\"Number of nan values in the whole df:\\n\", train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding 'Embarked & Sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, test_size = 0.2, shuffle = True)\n",
    "\n",
    "sc.fit(X_train)\n",
    "\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy is:  0.9030898876404494\n",
      "Test Accuracy is:  0.8324022346368715\n"
     ]
    }
   ],
   "source": [
    "#lr = LogisticRegression(random_state = 0)  # Test acc: 0.76076 with scaling\n",
    "                                           # Test acc: 0.75358 without scaling which is weird for me XD\n",
    "    \n",
    "#lr = MLPClassifier(hidden_layer_sizes = [100,10,10], random_state = 0, max_iter = 1000)  # Test acc: 0.7655 with scaling\n",
    "\n",
    "lr= GradientBoostingClassifier(random_state = 0)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train Accuracy is: \", lr.score(X_train, y_train))\n",
    "print(\"Test Accuracy is: \", lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./test.csv')\n",
    "test_data.index = test_data['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_Fszie_feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3f97a1757baf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_Fszie_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'create_Fszie_feature' is not defined"
     ]
    }
   ],
   "source": [
    "test_data = create_Fszie_feature(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Categorical Variables\n",
    "test_data = sex_embark_encode(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the encoding to be the same in both train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"male is encoded in train data as: \",train_data['Sex'][1])\n",
    "print(\"female is encoded in train data as: \",train_data['Sex'][2])\n",
    "\n",
    "print(\"male is encoded in test data as: \",test_data['Sex'][892])\n",
    "print(\"female is encoded in test data as: \",test_data['Sex'][893])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].dropna().mean()) # for test data\n",
    "\n",
    "mean_val= test_data['Age'].mean()\n",
    "test_data['Age']=test_data['Age'].fillna(mean_val)\n",
    "features_toDrop = ['Ticket', 'Cabin', 'Name', 'PassengerId']\n",
    "\n",
    "test_data = test_data.drop(features_toDrop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids = test_data.index\n",
    "test_data = sc.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit():\n",
    "    Y = lr.predict(test_data)\n",
    "    pred = {\"PassengerId\": Ids, \"Survived\": Y}\n",
    "    pred = pd.DataFrame(pred)\n",
    "    pred.to_csv('Subb.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
